from bgan.synthesizers.bgan import BGAN
from bayesian_network.DataSamplerBN import ColumnInfo, DataSamplerBN
from bayesian_network.BayesianGANInference import BayesianGANInference
from scipy.stats import ks_2samp
from scipy.spatial.distance import jensenshannon
import numpy as np
from ResearchQuestions.RQ_1.DataComparisonPlotter import DataComparisonPlotter

class BayesianGANPipeline:
    def __init__(self, data, output_info, bn_structure, discrete_columns, log_frequency=True, epochs=100, batch_size=500):
        """
        Initialize the Bayesian GAN pipeline.
        
        Args:
            data: The real dataset.
            output_info: Metadata about the dataset columns (e.g., discrete/continuous).
            bn_structure: The Bayesian Network structure for latent variable dependencies.
            discrete_columns: List of discrete columns in the dataset.
            log_frequency: Whether to use log frequency for categorical values.
            epochs: Number of training epochs for the BGAN.
            batch_size: Batch size for training.
        """
        self.data = data
        self.output_info = output_info
        self.bn_structure = bn_structure
        self.discrete_columns = discrete_columns
        self.log_frequency = log_frequency
        self.epochs = epochs
        self.batch_size = batch_size

        # Initialize the DataSamplerBN
        self.data_sampler = DataSamplerBN(
            data=data,
            output_info=output_info,
            log_frequency=log_frequency,
            bn_structure=bn_structure
        )

        # Initialize the BGAN
        self.bgan = BGAN(
            ########################################################################
            embedding_dim=len(self.data_sampler.bn_structure),  # Match the number of latent variables
            epochs=100, #FIXXXX, ONLY LIKE THIS FOR TESTING TO MAKE SURE PIPELINE WORKSSSSS!!!
            batch_size=500,
            verbose=True
            ########################################################################
        )

    def train(self):
        """
        Train the Bayesian GAN using the real dataset and Bayesian Network logic.
        """
        print("Training Bayesian GAN...")
        
        # Preprocess the data using the DataSamplerBN
        preprocessed_data = self.data_sampler.sample_data(self.data, len(self.data), None, None)
        
        # Train the BGAN
        self.bgan.fit(preprocessed_data, self.discrete_columns)
        print("Training complete!")

    def generate_synthetic_data(self, num_samples):
        """
        Generate synthetic data using the trained Bayesian GAN.
        
        Args:
            num_samples: Number of synthetic samples to generate.
        
        Returns:
            A DataFrame containing the synthetic data.
        """
        print(f"Generating {num_samples} synthetic samples...")
        
        # Generate synthetic data using the BGAN
        synthetic_data = self.bgan.sample(num_samples)
        
        print("Synthetic data generation complete!")
        return synthetic_data

    def evaluate(self, real_data, synthetic_data):
        """
        Evaluate the synthetic data by comparing it with the real data.
        
        Args:
            real_data: The real dataset.
            synthetic_data: The synthetic dataset generated by the Bayesian GAN.
        
        Returns:
            A dictionary containing evaluation metrics (e.g., KS test, JSD).
        """
        print("Evaluating synthetic data...")
        ks_results = {}
        jsd_results = {}

        for column in real_data.columns:
            if column in synthetic_data.columns:
                # KS Test
                ks_stat, p_value = ks_2samp(real_data[column], synthetic_data[column])
                ks_results[column] = {'ks_stat': ks_stat, 'p_value': p_value}

                # Jensen-Shannon Divergence
                jsd = self._compute_jsd(real_data[column], synthetic_data[column])
                jsd_results[column] = jsd

        print("Evaluation complete!")
        return {'ks_results': ks_results, 'jsd_results': jsd_results}

    def _compute_jsd(self, real, synthetic, bins=20):
        """
        Compute the Jensen-Shannon Divergence for a single column.
        
        Args:
            real: Real data column.
            synthetic: Synthetic data column.
            bins: Number of bins for histogram computation.
        
        Returns:
            The Jensen-Shannon Divergence value.
        """
        real_hist, _ = np.histogram(real, bins=bins, density=True)
        synthetic_hist, _ = np.histogram(synthetic, bins=bins, density=True)
        return jensenshannon(real_hist, synthetic_hist)

###############################################################
if __name__ == "__main__":
    from sklearn.preprocessing import LabelEncoder
    import pandas as pd

    # Example dataset
    data = pd.read_csv("http://ctgan-demo.s3.amazonaws.com/census.csv.gz")  # Replace with your dataset
    discrete_columns = [col for col in data.columns if data[col].dtype == 'object']

    # Encode categorical values
    le_dict = {}
    for col in discrete_columns:
        le = LabelEncoder()
        data[col] = le.fit_transform(data[col].astype(str))
        le_dict[col] = le

    # Define output_info
    output_info = [ColumnInfo(dim=1, activation_fn='softmax' if col in discrete_columns else 'tanh') for col in data.columns]

    # Define Bayesian Network structure
    bn_structure = {
        0: {'parents': []},
        1: {'parents': [0]},
        2: {'parents': [1]},
        3: {'parents': [2]},
        4: {'parents': [3]},
    }

    # Initialize the pipeline
    pipeline = BayesianGANPipeline(
        data=data,
        output_info=output_info,
        bn_structure=bn_structure,
        discrete_columns=discrete_columns,
        epochs=50,
        batch_size=256
    )

    # Train the Bayesian GAN
    pipeline.train()

    # Generate synthetic data
    synthetic_data = pipeline.generate_synthetic_data(num_samples=1000)

    # Initialize BayesianGANInference
    f = lambda x: x  # Example forward model
    sigma_noise = np.eye(data.shape[1]) * 0.1
    inference = BayesianGANInference(
        generator=pipeline.bgan._generator,
        data_sampler_bn=pipeline.data_sampler,
        f=f,
        sigma_noise=sigma_noise
    )

    # Perform inference tasks
    y_hat = np.random.rand(data.shape[1])  # Example observation
    mc_expectation = inference.monte_carlo_expectation(y_hat, l_func=lambda x: x)
    print("Monte Carlo Expectation:", mc_expectation)

